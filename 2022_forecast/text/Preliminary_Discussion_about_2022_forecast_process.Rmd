---
title: "Preliminary Discussion about the 2022 Forecast Process"
author: "Sara Miller"
date: "May 21, 2021"
output:
  bookdown::pdf_document2:
    fig_caption: yes
    toc: yes
header-includes:
 \usepackage{float}
---
```{r setup, echo = FALSE, warning = FALSE, message = FALSE, error = FALSE}
library(here)
library(fs)
library(tidyverse)
library(knitr)
library(ggplot2)
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE, error=FALSE)
year.forecast <- "2022_forecast" 
data.directory <- file.path(year.forecast, 'data', '/')
results.directory <- file.path(year.forecast, 'results', '/')
```

```{r data}

fs::dir_ls(here::here(results.directory), regexp = "\\.csv$") %>% 
  set_names(nm = (basename(.) %>% 
                    tools::file_path_sans_ext())) %>%
  map(read_csv) -> tbls_seak

```

# Objective
To determine the process for the 2022 Southeast Alaska (SEAK) preseason pink salmon forecast using data through 2020. 

# Executive Summary
Forecasts were developed using an approach originally described in Wertheimer et al. (2006), and modified in Orsi et al. (2016) and Murphy et al. (2019). We used a similar approach to Murphy et al. (2019), but assumed a log-normal error. This approach is based on a multiple regression model with juvenile pink salmon catch-per-unit-effort (CPUE) and temperature data from the Southeast Alaska Coastal Monitoring Survey (SECM; Murphy et al. 2020) or satellite sea surface temperature data (SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring, 5km, V.3.1, Monthly, 1985-Present’ time series (https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.html). Based on prior discussions, the index of juvenile abundance (i.e., CPUE) was based on the pooled-species vessel calibration coefficient.

Leave-one-out cross validation (hindcast) and model performance metrics were used to evaluate the forecast accuracy of models. These metrics included Akaike Information Criterion corrected for small sample sizes (AICc values; Burnham and Anderson 2004), the mean absolute scaled error (*MASE* metric; Hyndman and Kohler 2006), the weighted mean absolute percentage error (*wMAPE*; based on the last 5 years), leave one out cross validation *MAPE* (*MAPE_LOOCV*), one step ahead forecasts (*MAPE_one_step_ahead*) for the last five years (juvenile years 2015 through 2019), and significant coefficients (i.e., covariates) in the model. 

**Conclusions:**

* Overall, the performance metrics recommended models m13 (Chatham_Strait_SST_May), m16 (Icy_Strait_SST_May), m19 (NSEAK_SST_May), m20 (NSEAK_SST_AMJJ), and m22 (SST_Jordan_May). These five models were additive models with CPUE and a temperature variable.

* With the exclusion of juvenile years 1998 and 2016, the performance metrics still recommended models m13 (Chatham_Strait_SST_May), m16 (Icy_Strait_SST_May), m19 (NSEAK_SST_May), m20 (NSEAK_SST_AMJJ), and m22 (SST_Jordan_May).

# Analysis
## Hierarchical models
Forty five hierarchical models were investigated. The full model was:

$$E(y) = \alpha + \beta_1{X_1} + \beta_2{X_2} + \beta_3{X_1X_2},$$

where ${X_1}$ is the average CPUE for catches in either the June or July survey, whichever month had the highest average catches in a given year, and was based on the pooled-species vessel calibration coefficient, ${X_2}$ is a temperature index, and $\beta_3$ is the interaction term between CPUE and the temperature index. The CPUE data were log-transformed in the model, but temperature data was not. The simplest model did not contain a temperature variable (model m1). None of the interactions were significant (see Appendix Table 5 for detailed output); therefore only additive models (23 models; Table 1) were considered further. 
 
```{r coefficients}
tbls_seak$model_summary_table1 %>% 
   knitr::kable(format = 'pandoc', caption = 'Parameter estimates for the 23 potential models.', row.names = F)
```

## Performance metrics
The model summary results (Tables 2 and 3) using the performance metrics AICc, *MASE*, *wMAPE*, *MAPE_LOOCV*, and *MAPE_one_step_ahead* are shown in Table 2. For all of these metrics, the smallest value is the preferred model. Models with  $\Delta_i$AICc $\leq$ 2 have substantial support, those in which 4 $\leq$   $\Delta_i$AICc $\leq$  7 have considerably less support, and models with  $\Delta_i$AICc > 10 have essentially no support (Burnham and Anderson 2004). The performance metric *MAPE* was calculated as:

$$MAPE = \frac{1}{n} \sum_{t=1}^{n} |\frac{A_t-F_t}{A_t}|$$
where $A_t$ is the observed value and $F_t$ is the predicted value. The performance metric *wMAPE* was calculated as:

$$wMAPE =\sum_{t=1}^{n} \frac{1}{w_t} \sum_{t=1}^{n} |\frac{A_t-F_t}{A_t}|w_t.$$
where *w_t* is the weight for each year. For the *wMAPE* metric, the last 5 years (juvenile years 2015-2019) were given a weight of 1 and all other years, a weight of 0.001. Therefore, compared to the performance metric *MAPE_LOOCV*, the performance of the models in the last 5 years was given more weight in the *wMAPE* metric.  

The AICc in Table 2 is the AICc value and not the $\Delta_i$AICc. The performance metric AICc suggests that models m13, m16, and m19 are the recommended models (Table 2). The performance metrics *MASE* and *MAPE_LOOCV* suggest that models m13, m16, m19, and m22 are the recommended models (Table 2). The performance metric *wMAPE* suggests that models m16, m19, m20, and m22 are the recommended models (Table 2). The performance metric *MAPE_one_step_ahead* suggests that models m16, m20, and m22 are the recommended models (Table 2). Detailed outputs for recommended models m13, m16, m19, m20, and m22 are in the appendix (Tables 6 to 10 and Figures 2 through 11). 

```{r SummaryMetrics}
tbls_seak$model_summary_table5 %>% 
   knitr::kable(format = 'pandoc', caption = 'Summary of model outputs and forecast error measures. These metrics included Akaike Information Criterion corrected for small sample sizes (AICc values), the mean absolute scaled error (MASE metric), the weighted mean absolute percentage error (wMAPE; based on the last 5 years), leave one out cross validation MAPE (MAPE_LOOCV), and one step ahead forecasts (MAPE_one_step_ahead).', row.names = F)
```

```{r SummaryMetrics2}
tbls_seak$model_summary_table3 %>% 
   knitr::kable(format = 'pandoc', caption = 'Summary of model forecasts including the 80 percent prediction intervals (corrected for log transformation bias in a linear-model).', row.names = F)
```

\pagebreak
## Sensitivity analysis
A sensitivity analysis was done to determine if the juvenile years 1998 and 2016 were influential in the models. For the sensitivity analysis, juvenile years 1998 and 2016 (high leverage values in a majority of the five preferred models) were removed, the models rerun, and the performance metrics recalculated (Table 4).The performance metric AICc suggests that models m16 and m22 are the recommended model. The performance metrics *MASE* and *MAPE_LOOCV* suggest that models m13, m16, m19, and m22 are the recommended models. The performance metric *wMAPE* suggests that models m16, m19, m20, and m22 are the recommended models. The performance metric *MAPE_one_step_ahead* suggests that models m16, m20, and m22 are the recommended models. Therefore, based on the performance metrics, models m13, m16, m19, m20, and m22 are recommended.

```{r coefficients6}
tbls_seak$model_summary_table_sensitivity4 %>% 
   knitr::kable(format = 'pandoc', caption = 'Summary of model outputs and forecast error measures for the sensitivity analysis (exclusion of juvenile years 1998 and 2016). These metrics included Akaike Information Criterion corrected for small sample sizes (AICc values), the mean absolute scaled error (MASE metric), the weighted mean absolute percentage error (wMAPE; based on the last 5 years), leave one out cross validation MAPE (MAPE_LOOCV), and one step ahead forecasts (MAPE_one_step_ahead).', row.names = F)
```

\pagebreak

```{r coefficients7}
tbls_seak$model_summary_table_sensitivity3 %>% 
   knitr::kable(format = 'pandoc', caption = 'Summary of model forecasts including the 80 percent prediction intervals (corrected for log transformation bias in a linear-model) for the sensitivity analysis (exclusion of juvenile years 1998 and 2016).', row.names = F)
```

\pagebreak


```{r pred, echo=FALSE}
knitr::include_graphics(here(results.directory, "/forecast_models.png"))
```

Figure 1: The 2021 SEAK pink salmon harvest (millions) forecast by model. The 80% prediction intervals (corrected for log transformation bias in a linear-model) around each forecast were calculated using the car package (Fox and Weisberg 2019) in program R (R Core Team 2020). The dotted horizontal line is the average forecast across all models. The SEAK pink salmon harvest in 2021 (based on the November 18, 2020 advisory announcement) was a point estimate of 28 million fish (80% prediction interval: 19–42 million fish).

# References
Burnham, K. P., and D. R. Anderson. 2004. Multimodel inference: Understanding AIC and BIC in model selection. Sociological Methods and Research 33: 261-304.

Fox, J. and S. Weisburg. 2019. An R Companion to Applied Regression, Third Edition. Thousand Oaks CA: Sage Publications, Inc.

Hyndman, R. J. and A. B. Koehler. 2006. Another look at measures of forecast accuracy. International Journal of Forecasting 22: 679-688.

Murphy, J. M., E. A. Fergusson, A. Piston, A. Gray, and E. Farley.  2019. Southeast Alaska pink salmon growth and harvest forecast models.  North Pacific Anadromous Fish Commission Technical Report No. 15: 75-81.

NOAA Coral Reef Watch. 2021, updated daily. NOAA Coral Reef Watch Version 3.1 Monthly 5km SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring Time Series Data, May 1997-July 2020. College Park, Maryland, USA: NOAA/NESDIS/STAR Coral Reef Watch program. Data set accessed 2021-04-09 at https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.html.

Orsi, J. A., E. A. Fergusson, A. C. Wertheimer, E. V. Farley, and P. R. Mundy. 2016. Forecasting pink salmon production in Southeast Alaska using ecosystem indicators in times of climate change. N. Pac. Anadr. Fish Comm. Bull. 6: 483–499. (Available at https://npafc.org)

R Core Team. 2020. R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL: http://www.r-project.org/index.html 

Wertheimer A. C., J. A. Orsi, M. V. Sturdevant, and E. A. Fergusson. 2006. Forecasting pink salmon harvest in Southeast Alaska from juvenile salmon abundance and associated environmental parameters. In Proceedings of the 22nd Northeast Pacific Pink and Chum Workshop. Edited by H. Geiger (Rapporteur). Pac. Salmon Comm. Vancouver, British Columbia. pp. 65–72.

# Appendix
```{r coefficientsI}
tbls_seak$interaction_models %>% 
   knitr::kable(format = 'pandoc', caption = 'Parameter estimates for the 23 interaction models. None of the interactions were significant.', row.names = F)
```

```{r coefficients1}
tbls_seak$model_summary_table_m13%>% 
   knitr::kable(format = 'pandoc', caption = 'Detailed output for model m13. Fitted values are log-transformed.', row.names = F)
```

\pagebreak

```{r coefficients2}
tbls_seak$model_summary_table_m16 %>% 
   knitr::kable(format = 'pandoc', caption = 'Detailed output for model m16. Fitted values are log-transformed.', row.names = F)
```

\pagebreak

```{r coefficients3}
tbls_seak$model_summary_table_m19 %>% 
   knitr::kable(format = 'pandoc', caption = 'Detailed output for model m19. Fitted values are log-transformed.', row.names = F)
```

\pagebreak

```{r coefficients4}
tbls_seak$model_summary_table_m20 %>% 
   knitr::kable(format = 'pandoc', caption = 'Detailed output for model m20. Fitted values are log-transformed.', row.names = F)
```

\pagebreak

```{r coefficients5}
tbls_seak$model_summary_table_m22 %>% 
   knitr::kable(format = 'pandoc', caption = 'Detailed output for model m22. Fitted values are log-transformed.', row.names = F)
```

\pagebreak

```{r fitted1, echo=FALSE}
knitr::include_graphics(here(results.directory, "/fitted_m13.png"))
```

Figure 2: Standardized residuals versus the predicted plots for a) CPUE and b) temperature. c) Standardized residuals versus juvenile year and d) residuals versus fitted values for model m13. Relationship between e) temperature and harvest and f) CPUE and harvest. The line in figures a, b, d, e, and f is a smoothing function applied to the relationship with a 95% confidence interval.

```{r fitted2, echo=FALSE}
knitr::include_graphics(here(results.directory, "/fitted_m16.png"))
```

Figure 3: Standardized residuals versus the predicted plots for a) CPUE and b) temperature. c) Standardized residuals versus juvenile year and d) residuals versus fitted values for model m16. Relationship between e) temperature and harvest and f) CPUE and harvest. The line in figures a, b, d, e, and f is a smoothing function applied to the relationship with a 95% confidence interval.

```{r fitted3, echo=FALSE}
knitr::include_graphics(here(results.directory, "/fitted_m19.png"))
```

Figure 4: Standardized residuals versus the predicted plots for a) CPUE and b) temperature. c) Standardized residuals versus juvenile year and d) residuals versus fitted values for model m19. Relationship between e) temperature and harvest and f) CPUE and harvest. The line in figures a, b, d, e, and f is a smoothing function applied to the relationship with a 95% confidence interval.

```{r fitted4, echo=FALSE}
knitr::include_graphics(here(results.directory, "/fitted_m20.png"))
```

Figure 5: Standardized residuals versus the predicted plots for a) CPUE and b) temperature. c) Standardized residuals versus juvenile year and d) residuals versus fitted values for model m20. Relationship between e) temperature and harvest and f) CPUE and harvest. The line in figures a, b, d, e, and f is a smoothing function applied to the relationship with a 95% confidence interval.

```{r fitted5, echo=FALSE}
knitr::include_graphics(here(results.directory, "/fitted_m22.png"))
```

Figure 6: Standardized residuals versus the predicted plots for a) CPUE and b) temperature. c) Standardized residuals versus juvenile year and d) residuals versus fitted values for model m22. Relationship between e) temperature and harvest and f) CPUE and harvest. The line in figures a, b, d, e, and f is a smoothing function applied to the relationship with a 95% confidence interval.

```{r influential1, echo=FALSE}
knitr::include_graphics(here(results.directory, "/influential_m13.png"))
```

Figure 7: Diagnostics plots of influential observations including a) Cook’s Distance (with a cut-off value of
0.20), and b) leverage values (with a cut-off value of 0.26) from model m13.

```{r influential2, echo=FALSE}
knitr::include_graphics(here(results.directory, "/influential_m16.png"))
```

Figure 8: Diagnostics plots of influential observations including a) Cook’s Distance (with a cut-off value of
0.20), and b) leverage values (with a cut-off value of 0.26) from model m16.


```{r influential3, echo=FALSE}
knitr::include_graphics(here(results.directory, "/influential_m19.png"))
```

Figure 9: Diagnostics plots of influential observations including a) Cook’s Distance (with a cut-off value of
0.20), and b) leverage values (with a cut-off value of 0.26) from model m19.


```{r influential4, echo=FALSE}
knitr::include_graphics(here(results.directory, "/influential_m20.png"))
```

Figure 10: Diagnostics plots of influential observations including a) Cook’s Distance (with a cut-off value of
0.20), and b) leverage values (with a cut-off value of 0.26) from model m20.


```{r influential5, echo=FALSE}
knitr::include_graphics(here(results.directory, "/influential_m22.png"))
```

Figure 11: Diagnostics plots of influential observations including a) Cook’s Distance (with a cut-off value of
0.20), and b) leverage values (with a cut-off value of 0.26) from model m22.


\pagebreak

```{r sess_info, echo=FALSE}
#sessionInfo()
```
