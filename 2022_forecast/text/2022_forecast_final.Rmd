---
title: "SEAK Pink Salmon 2022 Forecast--final"
author: "Sara Miller"
date: "November 2, 2021"
output:
  pdf_document: default
  word_document: default
---
```{r setup, echo = FALSE, warning = FALSE, message = FALSE, error = FALSE}
library(here)
library(fs)
library(tidyverse)
library(knitr)
library(ggplot2)
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE, error=FALSE)
year.forecast <- "2022_forecast" 
data.directory <- file.path(year.forecast, 'data', '/')
results.directory <- file.path(year.forecast, 'results', '/')
```

```{r data}

fs::dir_ls(here::here(results.directory), regexp = "\\.csv$") %>% 
  set_names(nm = (basename(.) %>% 
                    tools::file_path_sans_ext())) %>%
  map(read_csv) -> tbls_seak

```

# Objective
To forecast the Southeast Alaska (SEAK) pink salmon commercial harvest in 2022. 

# Executive Summary
Forecasts were developed using an approach originally described in Wertheimer et al. (2006), and modified in Orsi et al. (2016) and Murphy et al. (2019).  We used a similar approach to Murphy et al. (2019), but assumed a log-normal error. This approach is based on a multiple regression model with juvenile pink salmon catch-per-unit-effort (CPUE) and temperature data from the Southeast Alaska Coastal Monitoring Survey (SECM; Piston et al. 2021). The final model used for the forecast was:
  
$$E(y) = \alpha + \beta_1{X_1} + \beta_2{X_2} + \epsilon,$$

where $y$ is log-transformed pink salmon harvest in SEAK, $\beta_1$ is the coefficient for CPUE using the pooled-species vessel calibration coefficient, $\beta_2$ is the coefficient for the environmental covariate water temperature, and $\epsilon$ represents the normally distributed error term. The CPUE data are the average log-transformed catches standardized to an effort of a 20 minute trawl set and calibrated to the fishing power of the NOAA Ship *John N. Cobb.* For each year, the standardized catch is either taken from June or July, whichever month had the highest average catches. Water temperature data is the average (May through July) temperature in the upper 20 m at the eight SECM stations in Icy Strait.

Leave-one-out cross validation (hindcast) and model performance metrics were used to evaluate the forecast accuracy of models. These metrics included Akaike Information Criterion corrected for small sample sizes (AICc values; Akaike 1973; Burnham and Anderson 2004), the mean absolute scaled error (MASE metric; Hyndman and Kohler 2006), the weighted mean absolute percentage error (wMAPE; based on the last 5 years), leave one out cross validation MAPE (MAPE_LOOCV), one step ahead forecasts (MAPE_one_step_ahead) for the last five years (years 2017 through 2021), and significant coefficients (i.e., covariates) in the model. Based on the all the performance metrics (AICc, MASE, wMAPE, MAPE_LOOCV, MAPE_one_step_ahead), the preferred model (i.e., the additive model with CPUE and temperature; model m2) predicted that the SEAK pink salmon harvest in 2022 will be in the weak range with a point estimate of 15.58 million fish (80% prediction interval: 10.30 to 23.57 million fish).

# Analysis

## Model data
The data used in the model are shown in table 1. 
```{r SummaryMetrics0}
tbls_seak$data_used %>% 
   knitr::kable(format = 'pandoc', caption = 'Model data.', row.names = F)
```

## Hierarchical models
Two hierarchical models were investigated. The full model was:

$$E(y) = \alpha + \beta_1{X_1} + \beta_2{X_2},$$

where ${X_1}$ is the average CPUE for catches in either the June or July survey, whichever month had the highest average catches in a given year, and was based on the pooled-species vessel calibration coefficient, and ${X_2}$ is a temperature index (i.e, average May through July temperature in the upper 20 m at the eight SECM stations in Icy Strait; ISTI20_MJJ). The CPUE data were log-transformed in the model, but temperature data were not. The simplest model did not contain a temperature variable (model m1). Parameter estimates are shown in table 2. 

```{r SummaryMetrics4}
tbls_seak$model_summary_table1 %>% 
   knitr::kable(format = 'pandoc', caption = 'Parameter estimates for the 2 models.', row.names = F)
```

## Performance metrics
The model summary results using the performance metrics AICc, MASE, wMAPE, MAPE_LOOCV, and MAPE_one_step_ahead ) are shown in table 3. For all of these metrics, the smallest value is the preferred model. Models with  $\Delta_i$AICc $\leq$ 2 have substantial support, those in which 4 $\leq$   $\Delta_i$AICc $\leq$  7 have considerably less support, and models with  $\Delta_i$AICc > 10 have essentially no support (Burnham and Anderson 2004). The performance metric MAPE was calculated as:

$$\mathrm {MAPE} = \frac{1}{n} \sum_{t=1}^{n} |\frac{A_t-F_t}{A_t}|$$
where $A_t$ is the observed value and $F_t$ is the predicted value. The performance metric wMAPE was calculated as:

$$\mathrm {wMAPE} =\sum_{t=1}^{n} \frac{1}{w_t} \sum_{t=1}^{n} |\frac{A_t-F_t}{A_t}|w_t.$$
where $w_t$ is the weight for each year. For the wMAPE metric, the last 5 years (juvenile years 2016-2020) were given a weight of 1 and all other years, a weight of 0.001. Therefore, compared to the performance metric MAPE_LOOCV, the performance of the model in the last 5 years was given more weight in the wMAPE metric. 

The performance metric MAPE_LOOCV uses five steps.

1. The dataset is split into a training set. The training set uses all but one observation of the full dataset.

2. Run the regression model based on the training set.

3. Use the regression model based on the training set to predict $F_t$ for the one observation left out of the model.

4. Repeat the process $n$ times based on the number of observations in the dataset, leaving out a different observation from the training set each time. 

5. Calculate MAPE, based on the average of all the training datasets (i.e., one MAPE is calculated for each training set and then these are averaged).

The performance metric MAPE_one_step_ahead involves three steps:

1. Estimate the regression parameters at time $t$ from data up to time $t-1$. 

2. Make a prediction of $F_t$ at time $t$ based on the predictor variables at time $t$ and the estimate of the regression parameters at time $t$.

3. Calculate the MAPE based on the prediction of $F_t$ at time $t$ and the observed value of $A_t$ at time $t$. 

4. Repeat this for data up through year 2016 (e.g., data up through year 2016 is $t-1$ and the forecast is for year 2017; $t$), data up through year 2017 (e.g., data up through year 2017 is $t-1$ and the forecast is for year 2018; $t$), data up through year 2018 to forecast 2019, data up through year 2019 to forecast 2020, and data up through year 2020 to forecast 2021.

3. The MAPE_one_step_ahead will then be an average of the MAPE calculated from these five forecasts. 

The AICc in table 3 is the AICc value and not the $\Delta_i$AICc. 
\pagebreak
```{r SummaryMetrics1}
tbls_seak$model_summary_table5 %>% 
   knitr::kable(format = 'pandoc', caption = 'Summary of model outputs and forecast error measures. These metrics included Akaike Information Criterion corrected for small sample sizes (AICc values), the mean absolute scaled error (MASE metric), the weighted mean absolute percentage error (wMAPE; based on the last 5 years), leave one out cross validation MAPE (MAPE_LOOCV), and one step ahead forecasts (MAPE_one_step_ahead).', row.names = F)
```

## Log transformation bias in a linear-model
To correct for log transformation bias in a linear-model, a bias correction (Miller 1984) was applied to the predicted 2022 SEAK harvest and its prediction interval (output from the car package (Fox and Weisberg 2019) in program R; R Core Team 2020; table 4) from each of the two models. The bias correction, applied to each value, is:

$$\hat{E}(Y_m) = \rm exp (\hat{\mu_m} + \frac{\hat{\sigma_m}^2}{2})$$
where ${\hat{\mu}}$ is the predicted value (or 80% upper or lower prediction interval value) from the individual model $m$. 

```{r SummaryMetrics2}
tbls_seak$model_summary_table3 %>% 
   knitr::kable(format = 'pandoc', caption = 'Summary of model forecasts including the 80 percent prediction intervals (corrected for log transformation bias in a linear-model).', row.names = F)
```


```{r pred, echo=FALSE}
knitr::include_graphics(here(results.directory, "/forecast_models.png"))
```

Figure 1: The 2022 SEAK pink salmon harvest (millions) forecast by model with 80% prediction intervals (corrected for log transformation bias in a linear-model) around each forecast. The SEAK pink salmon harvest in 2021 (based on the November 18, 2020 advisory announcement) was a point estimate of 28 million fish (80% prediction interval: 19â€“42 million fish; grey horizontal line).

## Model Diagnostics
Model diagnostics for model m2 included residual plots, the curvature test, and influential observation diagnostics using Cook's distance (Cook 1977), the Bonferroni outlier test, and leverage plots. Model diagnostics were used to identify observations that were potential outliers, had high leverage, or were influential (Zhang 2016). These observations may have significant impact on model fitting and may need to be excluded. 
\pagebreak
```{r details}
tbls_seak$model_summary_table4 %>% 
   knitr::kable(format = 'pandoc', caption = 'Detailed output for model m2. Juvenile years 1997, 1998, 2014, 2017, and 2020 (years 1998, 1999, 2015, 2018, 2021) show the largest standardized residual. Year refers to the forecast year. Fitted values are log-transformed.')
```

### Cook's distance
Cook's distance is a measure of influence, or the product of both leverage and outlier. Cook's distance,
$$D_i=\ \frac{e_{PSi}^2}{k+1}\ast\frac{h_i}{1-h_i},$$				
where $e_{PSi}^2$ is the standardized Pearson residuals, $h_i$ are the hat values (measure of leverage), and $k$ is the number of predictor variables in the model, is a measure of overall influence of the $i_{th}$ data point on all $n$ fitted values (Fox and Weisburg 2019). A large value of Cook's distance indicates that the data point is an influential observation. Cook's distance values greater than $4/(n-k-1)$, where $n$ is the number of observations (i.e., 24), was used as a benchmark for identifying the subset of influential observations (Ren et al. 2016). Therefore, a Cook's distance cut-off of 0.19 was used; observations with a Cook's distance greater than 0.19 were investigated further (Figure 2a). 

### Leverage
An observation that is distant from the average covariate pattern is considered to have high leverage or hat-value. If an individual observation has a leverage value $h_i$ greater than 2 or 3 times $p/n$ (Ren et al. 2016), it may be a concern (where $p$ is the number of parameters in the model including the intercept (i.e., 3), and $n$ is the number of observations in the model (i.e., 24); $p/n$ = 3/24 = 0.13 for this study). Therefore, a leverage cut-off of 0.26 was used; observations with a leverage value greater than 0.26 were investigated further (Figure 2b).

```{r influential, echo=FALSE}
knitr::include_graphics(here(results.directory, "/figs/influential.png"))
```

Figure 2: Diagnostics plots of influential observations including a) Cook's Distance (with a cut-off value of 0.19), and b) leverage values (with a cut-off value of 0.26) from model m2.

### Influential datapoints
To determine if a variable has a relationship with residuals, a lack-of fit curvature test was performed. In this test, terms that are non-significant suggest a properly specified model. The CPUE term was significant in the lack-of-fit curvature test ($P$<0.05), suggesting some lack of fit for this term (Figure 3a). Diagnostics indicated that two of the data points were above the cut-off value for the Cook's distance (Figure 2a). One observation had a high leverage value (Figure 2b). Based on the Bonferroni outlier test, none of the data points had a studentized residual with a significant Bonferroni $P$-value suggesting that none of the data points impacted the model fitting; although observations 1, 2, 18, 21, and 24 and were the most extreme (juvenile years 1997, 1998, 2014, 2017, and 2020 corresponding to years 1998, 1999, 2015, 2018, and 2021) based on standardized residuals (Figure 4a; Table 5). Based on the lightly curved fitted lines in the residual versus fitted plot (Figure 4b), the fitted plot shows some lack of fit of the model.

```{r predicted1, echo=FALSE}
knitr::include_graphics(here(results.directory, "/figs/predicted.png"))
```

Figure 3: Standardized residuals versus predicted plots for a) CPUE and b) temperature.

```{r fitted, echo=FALSE}
knitr::include_graphics(here(results.directory, "/figs/fitted.png"))
```

Figure 4: a) Standardized residuals versus juvenile year and b) residuals versus fitted values for model m2. Positive residuals indicate that the observed harvest was larger than predicted by the model.

## Results
The best regression model based on the performance metrics looked at and significant coefficients in the model was model m2 (i.e., the model containing CPUE, and a May through July temperature variable). The adjusted $R^2$ value for model m2 was 0.81 (Table 3) indicating overall a good model fit. Based upon a model that includes juvenile pink salmon CPUE and May through July temperature (model m2), the 2022 SEAK pink salmon harvest is predicted to be in the weak range with a point estimate of 15.58 million fish (80% prediction interval: 10.30 to 23.57 million fish). 

```{r predicted2, echo=FALSE}
knitr::include_graphics(here(results.directory, "/figs/catch_plot_pred.png"))
```

Figure 5: A) SEAK pink salmon harvest (millions) by year with the model fit (line). The predicted 2022 forecast is symbolized as a grey circle with an 80% prediction interval (10.30 to 23.57 million fish). B) SEAK pink salmon harvest (millions) against the fitted values from model m2 by year. The dotted line is a one to one line. 

# References
Akaike, H. 1973. Information theory and an extension of the maximum likelihood principle. In B. N. Pet rov & F. Caski (Eds.), Proceedings of the Second International Symposium on Information Theory (pp. 267-281). Budapest: Akademiai Kiado.

Burnham, K. P., and D. R. Anderson. 2004. Multimodel inference: Understanding AIC and BIC in model selection. Sociological Methods and Research 33: 261-304.

Cook, R. D. 1977. Detection of influential observations in linear regression. Technometrics 19: 15-18.

Fox, J. and S. Weisburg. 2019. An R Companion to Applied Regression, Third Edition. Thousand Oaks CA: Sage Publications, Inc.

Hyndman, R. J. and A. B. Koehler. 2006. Another look at measures of forecast accuracy. International Journal of Forecasting 22: 679-688.

Miller, D. M. 1984. Reducing transformation bias in curve fitting. The American Statistician 38: 124-126.

Murphy, J. M., E. A. Fergusson, A. Piston, A. Gray, and E. Farley.  2019. Southeast Alaska pink salmon growth and harvest forecast models.  North Pacific Anadromous Fish Commission Technical Report No. 15: 75-81.

Orsi, J. A., E. A. Fergusson, A. C. Wertheimer, E. V. Farley, and P. R. Mundy. 2016. Forecasting pink salmon production in Southeast Alaska using ecosystem indicators in times of climate change. N. Pac. Anadr. Fish Comm. Bull. 6: 483â€“499. (Available at https://npafc.org)

Piston, A. W., J. Murphy, J. Moss, W. Strasburger, S. C. Heinl, E. Fergusson, S. Miller, A. Gray, and C. Waters. 2021. Operational Plan: Southeast coastal monitoring, 2021. ADF&G, Regional Operational Plan No. ROP.CF.1J.2021.02, Douglas.

R Core Team. 2020. R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL: http://www.r-project.org/index.html 

Wertheimer A. C., J. A. Orsi, M. V. Sturdevant, and E. A. Fergusson. 2006. Forecasting pink salmon harvest in Southeast Alaska from juvenile salmon abundance and associated environmental parameters. In Proceedings of the 22nd Northeast Pacific Pink and Chum Workshop. Edited by H. Geiger (Rapporteur). Pac. Salmon Comm. Vancouver, British Columbia. pp. 65â€“72.

Zhang, Z. 2016. Residuals and regression diagnostics: focusing on logistic regression. Annals of Translational Medicine 4: 195. 


```{r sess_info, echo=FALSE}
#sessionInfo()
```
