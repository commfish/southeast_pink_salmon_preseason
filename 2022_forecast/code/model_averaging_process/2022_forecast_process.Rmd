---
title: "SEAK Pink Salmon 2022 Forecast Process"
author: "Sara Miller"
date: "October 5, 2021"
output: word_document
---
```{r setup, echo = FALSE, warning = FALSE, message = FALSE, error = FALSE}
library(here)
library(fs)
library(tidyverse)
library(knitr)
library(ggplot2)
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE, error=FALSE)
year.forecast <- "2022_forecast" 
data.directory <- file.path(year.forecast, 'data', '/')
results.directory <- file.path(year.forecast, 'results', '/')
```

```{r data}

fs::dir_ls(here::here(results.directory), regexp = "\\.csv$") %>% 
  set_names(nm = (basename(.) %>% 
                    tools::file_path_sans_ext())) %>%
  map(read_csv) -> tbls_seak

```

# Objective
To forecast the Southeast Alaska (SEAK) pink salmon commercial harvest in 2022. 

# Executive Summary
Forecasts were developed using an approach originally described in Wertheimer et al. (2006), and modified in Orsi et al. (2016) and Murphy et al. (2019). We used a similar approach to Murphy et al. (2019), but assumed a log-normal error. This approach is based on a multiple regression model with juvenile pink salmon catch-per-unit-effort (CPUE) and temperature data from the Southeast Alaska Coastal Monitoring Survey (SECM; Piston et al. 2021) or from satellite sea surface temperature data (SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring, (https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.html; https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW.html). See the document satellite_SST_process_5_Oct_2021 for details about the temperature variables. Based on prior discussions, the index of juvenile abundance (i.e., CPUE) was based on the pooled-species vessel calibration coefficient.

Leave-one-out cross validation (hindcast) and model performance metrics were used to evaluate the forecast accuracy of models. These metrics included Akaike Information Criterion corrected for small sample sizes (AICc values; Akaike 1973; Burnham and Anderson 2004), the mean absolute scaled error (*MASE* metric; Hyndman and Kohler 2006), the weighted mean absolute percentage error (*wMAPE*; based on the last 5 years), leave one out cross validation *MAPE* (*MAPE_LOOCV*), one step ahead forecasts (*MAPE_one_step_ahead*) for the last five years (years 2017 through 2021), and significant coefficients (i.e., covariates) in the model. The 2022 forecast was based on a model-averaged value using four methods.

**Conclusions:**  

The four potential methods for model-averaged forecast predictions for 2022 are:  

   * equal weighting of all eighteen models; 

   * inverse *MAPE_one_step_ahead* weighting of all eighteen models; 

   * equal weighting for models with *MAPE_one_step_ahead* <0.14; and 
   
   * equal weighting for models with $\Delta_i$ AICc $\leq$ 4.  
   
```{r SummaryMetrics3}
tbls_seak$model_summary_table6 %>% 
   knitr::kable(format = 'pandoc', caption = 'Summary of model-averaged forecasts including the 80 percent prediction intervals (corrected for log transformation bias in a linear-model).', row.names = F)
```

# Analysis

## Model data
The data used in the model are shown in table 2. 
```{r SummaryMetrics0}
tbls_seak$data_used %>% 
   knitr::kable(format = 'pandoc', caption = 'Model data. This does not include the temperature data.', row.names = F)
```

## Hierarchical models
Eighteen hierarchical models were investigated. The full model was:

$$E(y) = \alpha + \beta_1{X_1} + \beta_2{X_2},$$

where ${X_1}$ is the average CPUE for catches in either the June or July survey, whichever month had the highest average catches in a given year, and was based on the pooled-species vessel calibration coefficient, and ${X_2}$ is a temperature index. The CPUE data were log-transformed in the model, but temperature data were not. The simplest model did not contain a temperature variable (model m1; see Appendix for parameter estimates). 

## Performance metrics
The model summary results using the performance metrics AICc, *MASE*, *wMAPE*, *MAPE_LOOCV*, and *MAPE_one_step_ahead* (Table 3) are shown in table 4. For all of these metrics, the smallest value is the preferred model. Models with  $\Delta_i$AICc $\leq$ 2 have substantial support, those in which 4 $\leq$   $\Delta_i$AICc $\leq$  7 have considerably less support, and models with  $\Delta_i$AICc > 10 have essentially no support (Burnham and Anderson 2004). The performance metric *MAPE* was calculated as:

$$MAPE = \frac{1}{n} \sum_{t=1}^{n} |\frac{A_t-F_t}{A_t}|$$
where $A_t$ is the observed value and $F_t$ is the predicted value. The performance metric *wMAPE* was calculated as:

$$wMAPE =\sum_{t=1}^{n} \frac{1}{w_t} \sum_{t=1}^{n} |\frac{A_t-F_t}{A_t}|w_t.$$
where $w_t$ is the weight for each year. For the *wMAPE* metric, the last 5 years (juvenile years 2016-2020) were given a weight of 1 and all other years, a weight of 0.001. Therefore, compared to the performance metric *MAPE_LOOCV*, the performance of the model in the last 5 years was given more weight in the *wMAPE* metric. 

The performance metric *MAPE_LOOCV* uses five steps.

1. The dataset is split into a training set. The training set uses all but one observation of the full dataset.

2. Run the regression model based on the training set.

3. Use the regression model based on the training set to predict $F_t$ for the one observation left out of the model.

4. Repeat the process $n$ times based on the number of observations in the dataset, leaving out a different observation from the training set each time. 

5. Calculate *MAPE*, based on the average of all the training datasets (i.e., one *MAPE* is calculated for each training set and then these are averaged).

The performance metric *MAPE_one_step_ahead* involves three steps:

1. Estimate the regression parameters at time $t$ from data up to time $t-1$. 

2. Make a prediction of $F_t$ at time $t$ based on the predictor variables at time $t$ and the estimate of the regression parameters at time $t$.

3. Calculate the *MAPE* based on the prediction of $F_t$ at time $t$ and the observed value of $A_t$ at time $t$. 

4. Repeat this for data up through year 2016 (e.g., data up through year 2016 is $t-1$ and the forecast is for year 2017; $t$), data up through year 2017 (e.g., data up through year 2017 is $t-1$ and the forecast is for year 2018; $t$), data up through year 2018 to forecast 2019, data up through year 2019 to forecast 2020, and data up through year 2020 to forecast 2021.

3. The *MAPE_one_step_ahead* will then be an average of the *MAPE* calculated from these five forecasts. 

The AICc in Table 3 is the AICc value and not the $\Delta_i$AICc. 
\pagebreak
```{r SummaryMetrics1}
tbls_seak$model_summary_table5 %>% 
   knitr::kable(format = 'pandoc', caption = 'Summary of model outputs and forecast error measures. These metrics included Akaike Information Criterion corrected for small sample sizes (AICc values), the mean absolute scaled error (MASE metric), the weighted mean absolute percentage error (wMAPE; based on the last 5 years), leave one out cross validation MAPE (MAPE_LOOCV), and one step ahead forecasts (MAPE_one_step_ahead).', row.names = F)
```

\pagebreak

```{r SummaryMetrics2}
tbls_seak$model_summary_table3 %>% 
   knitr::kable(format = 'pandoc', caption = 'Summary of model forecasts including the 80 percent prediction intervals (corrected for log transformation bias in a linear-model).', row.names = F)
```

## Log transformation bias in a linear-model
To correct for log transformation bias in a linear-model, a bias correction (Miller 1984) was applied to the predicted 2022 SEAK harvest and its prediction interval (output from the car package (Fox and Weisberg 2019) in program R (R Core Team 2020)) from each of the eighteen models. The bias correction, applied to each value, is:

$$\hat{E}(Y_m) = \rm exp (\hat{\mu_m} + \frac{\hat{\sigma_m}^2}{2})$$
where ${\hat{\mu}}$ is the predicted value (or 80% upper or lower prediction interval value) from the individual model $m$. 

## Model averaging (multi-model inference)
The model-averaged forecast prediction for 2022 was based on four methods:  

   * equal weighting of all eighteen models; 

   * inverse *MAPE_one_step_ahead* weighting of all eighteen models; 

   * equal weighting for models with *MAPE_one_step_ahead* <0.14 (i.e., only 14 models included; models m1, m4, m8, m16 were excluded); and 
   
   * equal weighting for models with $\Delta_i$ AICc $\leq$ 4.  (i.e., only 5 models included; models m2, m3, m5, m11, m13 were included).
   
The calculation of the standard error of the model-averaged prediction (i.e., the square root of the unconditional variance estimator; equation 9 in Buckland et al. 1997; derivation in Burnham and Anderson 2002:159-162) is:

$$\widehat{\rm var}(\tilde{Y})=\left(\sum_{m=1}^{M}{w_m}\sqrt{\widehat{\rm var}(\hat{Y_m})+\gamma_m^2}\right)^2$$

where $\tilde{Y}$ is the model-averaged estimate (or prediction), $\hat{Y_m}$ is the individual model $m$ output, and $\gamma_m$ (i.e., the misspecification bias of model $m$) is computed as $\gamma_m =\hat{Y_m}- \tilde{Y}$. The prediction interval is then calculated as:
$$\tilde{Y} \pm z_{1-\alpha/2}\widehat{\rm se}(\tilde{Y})$$
where $\widehat{\rm se}(\tilde{Y})=\sqrt{\widehat{\rm var}(\tilde{Y})}$, and $z_{1-\alpha/2}=1.28$. 

```{r pred, echo=FALSE}
knitr::include_graphics(here(results.directory, "/forecast_models.png"))
```

Figure 1: The 2022 SEAK pink salmon harvest (millions) forecast by model with 80% prediction intervals (corrected for log transformation bias in a linear-model) around each forecast. The dotted horizontal lines are the model-averaged forecast across all models based on the four methods. The SEAK pink salmon harvest in 2021 (based on the November 18, 2020 advisory announcement) was a point estimate of 28 million fish (80% prediction interval: 19–42 million fish; grey horizontal line).

# References
Akaike, H. 1973. Information theory and an extension of the maximum likelihood principle. In B. N. Pet rov & F. Caski (Eds.), Proceedings of the Second International Symposium on Information Theory (pp. 267-281). Budapest: Akademiai Kiado.

Buckland, S.T., K. P. Burnham, and N. H. Augustin. 1997. Model selection: an integral part of inference. Biometrics: 603-618.

Burnham, K. P., and D. R. Anderson, D. R. 2002. Model selection and multimodel inference: A practical information-theoretic approach. Second Edition. New York: Springer-Verlag

Burnham, K. P., and D. R. Anderson. 2004. Multimodel inference: Understanding AIC and BIC in model selection. Sociological Methods and Research 33: 261-304.

Fox, J. and S. Weisburg. 2019. An R Companion to Applied Regression, Third Edition. Thousand Oaks CA: Sage Publications, Inc.

Hyndman, R. J. and A. B. Koehler. 2006. Another look at measures of forecast accuracy. International Journal of Forecasting 22: 679-688.

Miller, D. M. 1984. Reducing transformation bias in curve fitting. The American Statistician 38: 124-126.

Murphy, J. M., E. A. Fergusson, A. Piston, A. Gray, and E. Farley.  2019. Southeast Alaska pink salmon growth and harvest forecast models.  North Pacific Anadromous Fish Commission Technical Report No. 15: 75-81.

NOAA Coral Reef Watch (NOAA_DHW_monthly dataset). 2021, updated daily. NOAA Coral Reef Watch Version 3.1 Monthly 5km SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring Time Series Data, May 1997-June 2021. College Park, Maryland, USA: NOAA/NESDIS/STAR Coral Reef Watch program. Data set accessed 2021-10-01 at https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.html.

NOAA Coral Reef Watch (NOAA_DHW dataset). 2021, updated daily. NOAA Coral Reef Watch Daily Near-real-Time Global 5km SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring Time Series Data, July 2021. College Park, Maryland, USA: NOAA/NESDIS/STAR Coral Reef Watch program. Data set accessed 2021-10-01 at https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW.html.

Orsi, J. A., E. A. Fergusson, A. C. Wertheimer, E. V. Farley, and P. R. Mundy. 2016. Forecasting pink salmon production in Southeast Alaska using ecosystem indicators in times of climate change. N. Pac. Anadr. Fish Comm. Bull. 6: 483–499. (Available at https://npafc.org)

Piston, A. W., J. Murphy, J. Moss, W. Strasburger, S. C. Heinl, E. Fergusson, S. Miller, A. Gray, and C. Waters. 2021. Operational Plan: Southeast coastal monitoring, 2021. ADF&G, Regional Operational Plan No. ROP.CF.1J.2021.02, Douglas.

R Core Team. 2020. R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL: http://www.r-project.org/index.html 

Wertheimer A. C., J. A. Orsi, M. V. Sturdevant, and E. A. Fergusson. 2006. Forecasting pink salmon harvest in Southeast Alaska from juvenile salmon abundance and associated environmental parameters. In Proceedings of the 22nd Northeast Pacific Pink and Chum Workshop. Edited by H. Geiger (Rapporteur). Pac. Salmon Comm. Vancouver, British Columbia. pp. 65–72.

\pagebreak

# Appendix

```{r SummaryMetrics4}
tbls_seak$model_summary_table1 %>% 
   knitr::kable(format = 'pandoc', caption = 'Parameter estimates for the 18 models.', row.names = F)
```



```{r sess_info, echo=FALSE}
#sessionInfo()
```
